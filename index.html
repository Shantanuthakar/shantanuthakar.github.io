<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"">

    <title>Shantanu Thakar</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet">
    <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/resume.min.css" rel="stylesheet">

  <style type="text/css">
  .mobileShow {display: none;}

  /* Smartphone Portrait and Landscape */
  @media only screen
    and (min-device-width : 320px)
    and (max-device-width : 770px){
      .mobileShow {display: inline;}
  }
</style>

  </head>

  <body id="page-top">

    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
      <a class="navbar-brand js-scroll-trigger" href="#page-top">
        <span class="d-block d-lg-none">Shantanu Thakar</span>
        <span class="d-none d-lg-block">
          <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/profilepic2.jpg" alt="">
        </span>

      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>

      <div class="collapse navbar-collapse" id="navbarSupportedContent">

       <div class="mobileShow">

<img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/profile2.jpg" alt="" style="width:100px;height:100px;">

       </div>
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#about">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#research">research</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#robots">Robots</a>
          </li>
        </ul>
      </div>
    </nav>

    <div class="container-fluid p-0">

      <section class="resume-section p-3 p-lg-5 d-flex d-column" id="about">
        <div class="my-auto">
          <h1 class="mb-0">Shantanu
            <span class="text-primary">Thakar</span>
          </h1>
           <p class="lead mb-5">
                 <span class="text-primary">Email </span> : shantanuthakar -at- gmail -dot- com<br />
           </p>
          <p class="lead mb-0"> I am Applied Scientist working at Amazon Lab126 since June 2021. I completed my PhD in Mechanical Engineering with a focus on Robotics from USC. I was advised by a <a href="http://ruk.usc.edu/bio/gupta/" target="_blank">Prof. Satyandra K. Gupta</a> at the <a href="https://www.rros-usc.net/" target="_blank">Realization of Robotic Systems Laboratory</a> based out of the Center for Advanced Manufacturing at USC. My research interests include Artificial Intelligence for robotic motion planning and machine learning.<br />
          

          <br/>
		  The applications I worked on include trajectory planning of high degree of freedom robotic systems like mobile manipulators, high speed grasping of objects, area-coverage planning and constrained trajectory generation. A full list of my publications can be found <a href="https://scholar.google.com/citations?user=xcwnsqAAAAAJ&hl=en">here.</font></a> </p><br />
          <br />
          <br />
          <div class="social-icons">
            <a href="https://www.linkedin.com/in/shantanuthakar/">
              <i class="fab fa-linkedin-in"></i>
            </a>
<!--             <a href="https://scholar.google.com/citations?user=xcwnsqAAAAAJ&hl=en">
              <i class="fab fa-googlescholar"></i>
            </a> -->
<!--             <a href="#">
              <i class="fab fa-github"></i>
            </a> -->
          </div>
        </div>
      </section>
	  
			  
			  
      <hr class="m-0">

      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="research">
        <div class="my-auto">
          <h2 class="mb-5">Research</h2>
		   <div class="resume-item d-flex flex-column flex-md-row mb-5">
			<div class="resume-content mr-auto">
			  <h3 class="mb-0">COVID-19 Disinfection Robot (ADAMMS-UV)</h3>
			  <div class="subheading mb-3">Summary </div>
			  <p class="lead mb-0">
				Led a team of researchers for the development of ADAMMS-UV (Agile Dexterous Autonomous Mobile Manipulation System-UV), a semi-autonomous mobile manipulator to perform disinfection tasks in public spaces such as offices, labs, schools, hotels, and dorms using UV light. The UV light mounted robots currently in markets have a UV column on a mobile base that goes around in rooms and stands still at certain places in the room so that surfaces that are exposed to the light are disinfected. ADAMMS-UV is a semi-autonomous mobile manipulator that uses a UV light wand mounted on a robotic arm to reach spaces that cannot be treated by such UV source mounted robots. In addition, it also has a large UV light source to disinfect large open spaces. It can use the gripper to open drawers, closets and manipulate objects to perform a detailed sanitization on hard to reach surfaces. UV light is a proven disinfectant. Coronavirus on a surface can be killed when exposed to UV light of appropriate intensity for a sufficient amount of time. ADAMMS-UV can hold a UV wand over a surface and move it the right speed. The robot can do this task consistently without making any mistake. This task will be physically taxing and risky for humans.  <br/>
				</p><br/>
				<p class="lead mb-0"> 
				ADAMMS-UV was featured on <a href="https://www.forbes.com/sites/richblake1/2020/04/17/in-covid-19-fight-robots-report-for-disinfection-duty/#468db3d12ada" target="_blank">Forbes.com</a>, <a href="https://spectrum.ieee.org/news-from-around-ieee/the-institute/ieee-member-news/usc-researchers-robotic-arm-disinfect-coronavirus" target="_blank">IEEE Spectrum and The Institute Magazines</a>, <a href="https://www.nbcbayarea.com/news/coronavirus/robots-join-fight-against-covid-19/2272876/" target="_blank">NBC</a>, <a href="https://go.forrester.com/blogs/forrward-a-weekly-read-for-tech-and-marketing-execs-11/" target="_blank">Forrester Market Research</a>, <a href="https://mashable.com/video/uv-light-wand-robot-disinfect-public-spaces/" target="_blank">Mashable.com</a>, <a href="https://dailytrojan.com/2020/04/24/students-modify-robot-for-remote-disinfection/" target="_blank">Daily Trojan</a>, <a href="https://www.newsbreak.com/news/0Om8i1G4/viterbi-researchers-build-robot-to-fight-coronavirus" target="_blank">News Break</a>, <a href="https://viterbischool.usc.edu/news/2020/04/robotic-arms-extend-the-reach-of-uv-disinfection/" target="_blank">USC Viterbi School News</a> and <a href="http://www.uscannenbergmedia.com/2020/04/16/viterbi-researchers-build-robot-to-fight-coronavirus/" target="_blank">USC Annenberg Media</a> 
				</p><br/>
				<iframe   margin:0 width="512" height="285" src="https://www.youtube.com/embed/-YdsP9M-Luw" frameborder="0" ; allowfullscreen></iframe>
			</div>
			  <div class="resume-date text-md-right">
				<span class="text-primary">April 2020</span>
			  </div>
		    </div>
		    
		    
		    <div class="resume-item d-flex flex-column flex-md-row">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Area-coverage planning for spray-based disinfection with a mobile manipulator (ADAMMS-SD)   </h3>
              <div class="subheading mb-3">Summary </div>
              <p class="lead mb-0">
                  Manual disinfection can be a time-consuming, risky, labor-intensive, and mundane, and humans may fail to disinfect critical areas due to the resulting fatigue. Autonomous or semi-autonomous mobile manipulators mounted with a spray nozzle at the end-effector can be very effective in spraying disinfectant liquid for deep disinfection of objects and surfaces. Such a robot must autonomously perceive the surface to be disinfected, plan for paths of the nozzle to spray the entire surface, and execute the motion of the robot to follow this path. In this work, we present a framework to disinfect surfaces represented by their point clouds and execute motions with a mobile manipulator. The first step is to project the point cloud on a plane and generate a polygon. On the polygon, we then generate multiple spray paths using our branch and bound-based tree search algorithms such that the spray paths cover the entire area of the polygon and reduce wastage of spray disinfectant. An appropriate spray path is chosen using a robot capability map-based selection criterion. We generate mobile manipulator trajectories using successive refinement-based parametric optimization so that the paths for the nozzle are followed accurately. Once we have the mobile manipulator path that results in the spray nozzle following the chosen spray path, we need to make sure that the joint velocities of the mobile manipulator are regulated appropriately such that each point on the surface receives enough disinfectant spray. To this end, we compute the time intervals between the robot path waypoints such that enough disinfectant liquid is sprayed on all points of the point cloud that results in thorough disinfection of the surface, and the particular robot path is executed in the minimum possible time. We have implemented this framework and methodologies on five test scenarios in simulation using our ADAMMS-SD (Agile Dexterous Autonomous Mobile Manipulation System for Surface Disinfection) robot. 

              </p><br/>
            
            <img width="465" height="280" src="adamms_sd.png" alt="">
            </div>
            <div class="resume-date text-md-right">
                <span class="text-primary">Jan 2021</span>
            </div>
          </div><br/>
		  
		  

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Global Trajectory Planning for Part Transport using Mobile Manipulators</h3>
              <div class="subheading mb-3">Summary </div>
              <p class="lead mb-0">
                We introduce an algorithm for path planning for a mobile manipulator in a global sense. The mobile manipulator has to start from an initial location, pick up a part and go to the goal location in the minimum time. We define Grasping Area as an area around the part, in which if the robot is located, the manipulator can reach to grasp the part. The planning algorithm for the mobile base is a search based scheme with heuristics designed to bias the search towards the Grasping Area initially and then towards the goal after the part has been picked up. The time taken by the manipulator to pick up the part is added to the cost to go of certain nodes in the search tree. For the manipulator, we have implemented an inverse kinematics based planner.<br/>
                Key Points :
                <ul class="lead mb-3">
                  <li style="color:#343a40;font-size:1.15rem;">A single planner for the motion from start to goal via grasping area</li>
                  <li style="color:#343a40;font-size:1.15rem;">Any Manipulator planner can be integrated with this</li>
                  <li style="color:#343a40;font-size:1.15rem;">Capable of picking up parts while mobile base is translating, turning or stationary</li>
                </ul>
                </p>
                <p class="lead mb-0">The paper can be found <a href="ThakarCASE2018.pdf">here</a></p><br/>
                <iframe   margin:0 width="512" height="285" src="https://www.youtube.com/embed/B4SumiabVus" frameborder="0" ; allowfullscreen></iframe>
            </div>
              <div class="resume-date text-md-right">
                <span class="text-primary">March 2018</span>
              </div>
              </div>
      <!--     </div>
          <iframe  vspace="" margin:0 width="512" height="285" src="https://www.youtube.com/embed/B4SumiabVus" frameborder="0" ;padding: 0px 0; allowfullscreen></iframe>
          </div> -->
          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Manipulator Motion Planning for Part Pick-up and Transport Operations from a Moving Base</h3>
              <div class="subheading mb-3">Summary </div>
              <p class="lead mb-0">
				In the previous work, we presented a global searcg based algorithm for the motion planning of the mobile base for part pick-up and transportation. We assumed that the manipulator motion is simplistic and used only as a heuristic to determine the approximate time-delay it adds to the mobile base motion. In this work, we plan for the manipulator motion in a cluttered environment. We present a planning framework to determine when the manipulator motion should begin and end and where grasping should begin and end. Further, we present 3 techniques to improve computation time and decrease the time the manipulator is in motion along the mobile base path. Here the grasping happens when the gripper is stationary with respect to the part and the manipulator conpensates for the motion of the mobile base as it moves along its pre-defined trajectory. The video shows the resulting motions of the manipulator. 
                </p><br/>
                <iframe   margin:0 width="512" height="285" src="https://www.youtube.com/embed/Du-2Hn2j1Y8" frameborder="0" ; allowfullscreen></iframe>
            </div>
              <div class="resume-date text-md-right">
                <span class="text-primary">2019-20</span>
              </div>
		    </div>
			  
			  
          <div class="resume-item d-flex flex-column flex-md-row">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Local Trajectory Planning of Mobile Manipulators for Time-Optimal Part-Pick Up with a Moving Gripper</h3>
               <div class="subheading mb-3">Summary </div>
              <p class="lead mb-0">
                  We have developed an optimization based algorithm for trajectory planning of mobile manipulator, such that the gripper attached to the end-effector follows a trajectory so as to have a desired probability of grasping of a part under pose uncertainty. Each DoF of the robot is a polynomial in time and the parameters are the optimization variables. The constraints on the system include the non-holonomic motion of the mobile base, the joint and rate limits for each joint, the gripper velocity constraints and the minimum probability constraints for successful grasping. The objective function is the trajectory time. Finally, a sequential refinement based non-linear optimization is implemented by successively adding constraints.
                <br/>
                Key Points :
                <ul class="lead mb-3">
                  <li style="color:#343a40;font-size:1.15rem;">This is a local planner and can be used as a motion primitive for the previous global graph search based planner</li>
                  <li style="color:#343a40;font-size:1.15rem;">The mobile robot compensates for the motion of the gripper</li>
                  <li style="color:#343a40;font-size:1.15rem;">Results in picking of parts while in motion</li>
                </ul>
                </p><br/>
                <p class="lead mb-0">The paper can be found <a href="ThakarICRA2019.pdf">here</a></p><br/> 
                <iframe   margin:0; width="512" height="285" src="https://www.youtube.com/embed/8fWLFA97TCo" frameborder="0" ; allowfullscreen></iframe>
            </div>
              <div class="resume-date text-md-right">
                <span class="text-primary">September 2018</span>
              </div>
              </div><br/>

          <!-- <object width="425" height="344" data="https://www.youtube.com/watch?v=8fWLFA97TCo"></object> -->
          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Active Learning for High Speed Grasping under Pose Uncertainty</h3>
              <div class="subheading mb-3">Summary </div>
              <p class="lead mb-0">
                The probability constraints mentioned in the previous summary is described here. We build a probability meta model for successful grasping of parts under pose uncertainty with a moving gripper for various gripper speeds and gripper closing speeds. For this we use SVM based active learning to create a boundary between successful and failed part poses for a pair of gripper speed and closing speed. This vastly decreases the number of simulations required to determine the probability for a given level of uncertainty as compared to Monte Carlo simulations. A details of this and the above trajectory planning is shown in the following video.
			  </p><br/>
			  <p class="lead mb-0">The paper can be found <a href="ThakarICRA2019.pdf">here</a></p><br/>
			  <p class="lead mb-0">More information on this work can be found <a href="https://sites.google.com/view/icra2019thakar/home">here</a></p><br/>
                <video controls
                       muted
                       src="icra2019thakar_final_video.mp4"
                       width="512"
                       height="285"
                       frameborder="0">
                    Sorry, your browser doesn't support embedded videos.
                </video>
            </div>
              <div class="resume-date text-md-right">
                <span class="text-primary">September 2018</span>
              </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Constrained Trajectory Planning for High DoF Systems</h3>
              <div class="subheading mb-3">Summary </div>
              <p class="lead mb-0">
                We pose the problem of path-constrained trajectory generation for synchronous motion of multi-robot systems as a non-linear optimization problem. Our method determines appropriate parametric representation for the configuration variables, generates an approximate solution as a starting point for the optimization method, and uses successive refinement techniques to solve the problem in a computationally efficient manner. We have demonstrated the effectiveness of the proposed method on challenging simulation and physical experiments with high degrees of freedom robotic systems.
              </p><br/>
              <iframe   margin:0; width="512" height="285" src="https://www.youtube.com/embed/bD7FItjOWY0" frameborder="0" ; allowfullscreen></iframe>
            </div>
              <div class="resume-date text-md-right">
                <span class="text-primary">September 2018</span>
              </div>
          </div>


          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Task Assignment and Motion Planning for Bi-Manual Mobile Manipulation</h3>
              <div class="subheading mb-3">Summary </div>
              <p class="lead mb-0">
                We  present  a  two-layered  architecture  for  task-agent  assignment  and  motion  planning  of  Bi-manual  Mobile manipulators for executing complex tasks. We use search trees in temporal windows to determine feasible task assignments ofagents  using  task  and  spatial  constraint-based  heuristics.  We also  introduce  a  caching  scheme  for  moving  between  different trees  so  as  to  avoid  re-planning  of  those  portions  of  the  robot motion  that  were  successful.  This  greatly  reduces  the  number of  calls  to  the  motion  planner  as  compared  to  direct  motion planning   after   task-agent   assignment.   We   have   shown   our approach  works  on  a  set  of  complex  tasks  with  significantly lower  computation  times.
			  </p><br/>
			  <p class="lead mb-0">
				Multi-arm mobile manipulators can be represented as a combination of multiple robotic agents from the perspective of task-assignment and motion planning. Depending upon the task, agents might collaborate or work independently. Integrating motion planning with task-agent assignment is a computationally slow process as infeasible assignments can only be detected through expensive motion planning queries. We present three speed-up techniques for addressing this problem- (1) spatial constraint checking using conservative surrogates for motion planners, (2) instantiating symbolic conditions for pruning infeasible assignments, and (3) efficiently caching and reusing previously generated motion plans. We show that the developed method is useful for real-world operations that require complex interaction and coordination among high-DOF robotic agents.
              </p><br/>
			  <p class="lead mb-0">The paper can be found <a href="ThakarCASE2019.pdf">here</a></p><br/>
                <video controls
                       muted
                       src="CASE2019BIMM.mp4"
                       width="512"
                       height="285"
                       frameborder="0">
                    Sorry, your browser doesn't support embedded videos.
                </video>
              <iframe   margin:0; width="512" height="285" src="https://www.youtube.com/embed/Ba6xDjjWvsQ" frameborder="0" ; allowfullscreen></iframe>
            </div>
              <div class="resume-date text-md-right">
                <span class="text-primary">March 2019</span>
              </div>
          </div>


          <div class="resume-item d-flex flex-column flex-md-row">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Sampling-based point-to-point motion planning for nonholonomic mobile manipulators</h3>
              <div class="subheading mb-3">Summary </div>
              <p class="lead mb-0">
                Determining a feasible path for a nonholonomic mobile manipulator operating in congested environments is challenging. Sampling-based methods, especially bi-directional tree search based approaches are amongst the most promising candidates for quickly finding feasible paths. However, sampling uniformly when using these methods may result in high computation time for nonholonomic mobile manipulator motion planning. This paper introduces two techniques to accelerate the motion planning. The first one is coordinated focusing for the manipulator and the mobile base based on the information from robot surroundings. The second one is a heuristic for making connections between the two search trees, which is challenging owing to the nonholonomic constraints on the mobile base. Incorporating these two techniques into the bi-directional RRT framework, results in about 5x faster and 10x more successful computation of paths as compared to the baseline method.
                </p><br/>
                <video controls
                       muted
                       src="iros_2020_final_submitted.mp4"
                       width="512"
                       height="285"
                       frameborder="0">
                    Sorry, your browser doesn't support embedded videos.
                </video>
				<video controls
                       muted
                       src="ICRA_2020_VIDEO_2_comp.mp4"
                       width="512"
                       height="285"
                       frameborder="0">
                    Sorry, your browser doesn't support embedded videos.
                </video><br/>
            </div>
            <div class="resume-date text-md-right">
                <span class="text-primary">March 2020</span>
            </div>
          </div>
        




          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Context-Dependent Search for Generating Paths for Redundant Manipulators in Cluttered Environments</h3>
              <div class="subheading mb-3">Summary </div>
              <p class="lead mb-0">
                We present a context-dependent bi-directional tree-search framework for point-to-point path planning for manipulators. Conceptually, our framework is composed of six modules: tree selection, focus selection, node selection, target selection, extend selection and connection type selection. Each module consists of a set of interchangeable strategies. By exploiting synergistic interaction between these strategies and selecting appropriate strategies based the contextual cues from the search state, we show an instance of our framework that computes high-quality solutions in a variety of complex scenarios with a low failure rate. We also show that some popular path planning methods in the literature can be easily represented in our framework. We compare our approach with these popular methods in a diverse set of test scenarios. We report a 15-fold reduction in failure rate coupled with at least a 26% drop in solution sub-optimality when compared to the best of the alternative methods.
              </p><br/>
              <iframe   margin:0; width="512" height="285" src="https://www.youtube.com/embed/3jRMUIE-tEU" frameborder="0" ; allowfullscreen></iframe>
            </div>
              <div class="resume-date text-md-right">
                <span class="text-primary">March 2020</span>
              </div>
          </div>


          <div class="resume-item d-flex flex-column flex-md-row">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Virtual Target based Path Following</h3>
              <div class="subheading mb-3">Summary </div>
              <p class="lead mb-0">
                  A new guidance logic for UAV path following using a virtual target is presented. The
                  desired heading of the UAV follows an instantaneous circular arc which is tangential to
                  the path at the virtual target position. Considering straight line and circular paths, a
                  linear analysis of the resulting error dynamics presents a faster convergence as compared
                  to existing methods. With no overshoot in the response, the method presents smooth
                  following for higher look-ahead distances with respect to the virtual target. Comparative
                  simulations are carried out complying with the analytic findings. The work highlights a
                  simple guidance logic with a faster convergence and greater robustness with respect choice
                  of the virtual target.
              </p><br/>
            <p class="lead mb-0">The paper can be found <a href="aiaa_paper.pdf">here</a></p><br/>
            <img width="690" height="280" src="tan_guidance.png" alt="">
            </div>
            <div class="resume-date text-md-right">
                <span class="text-primary">Aug 2015 - Mar 2016</span>
            </div>
          </div><br/>

          <div class="resume-item d-flex flex-column flex-md-row">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Design and Navigation of Spherical Robot</h3>
              <div class="subheading mb-3">Summary </div>
              <p class="lead mb-0">
                The project invloved designing of a yoke and double pendulum actuated spherical robot. A PID control based turning motion primitive is designed to navigate the robot. Overhead cameras indoors and GPS outdoors along with IMU give the position of the robot. Patent for the design of the robot is pending.
              </p><br/>
                <video controls
                       muted
                       src="spherical_robot.mp4"
                       width="512"
                       height="285"
                       frameborder="0">
                    Sorry, your browser doesn't support embedded videos.
                </video>
            </div>
            <div class="resume-date text-md-right">
                <span class="text-primary">Jul 2014 - May 2015</span>
            </div>
          </div>
        </div>

      </section>

      <hr class="m-0">
<!--
      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="education">
        <div class="my-auto">
          <h2 class="mb-5">Education</h2>

          <div class="resume-item d-flex flex-column flex-md-row mb-5">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">University of Southern California</h3>
              <div class="subheading mb-3">PhD</div>
              <div>Mechanical Engineering - Specilization : Robotics</div>
              <p>GPA: 3.67</p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">August 2016 - Current</span>
            </div>
          </div>

          <div class="resume-item d-flex flex-column flex-md-row">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Indian Institute of Technology Bombay</h3>
              <div class="subheading mb-3">Bachelor and Master of Technology</div>
              <div>Mechanical Engineering - Specilization : Automation</div>
              <p>GPA: 8.31</p>
            </div>
            <div class="resume-date text-md-right">
              <span class="text-primary">July 2010 - May 2015</span>
            </div>
          </div>

        </div>
      </section> -->
    <hr class="m-0">

      <section class="resume-section p-3 p-lg-5 d-flex flex-column" id="robots">

        <div class="my-auto">
          <h2 class="mb-5">Robots</h2>
          <div class="resume-item d-flex flex-column flex-md-row">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">Mobile MAnipulator</h3>
              <div class="subheading mb-3"> </div>
              <p class="lead mb-0">
                Inspector Bot + UR5 + Robotiq 2-fingered gripper. Git repo coming soon.
                </p><br/>
              <img width="520" height="290" src="mm.png" alt="">
            </div>
          </div><br/>

          <div class="resume-item d-flex flex-column flex-md-row">
            <div class="resume-content mr-auto">
              <h3 class="mb-0">KUKA iiwa 14</h3>
              <div class="subheading mb-3"> </div>
              <p class="lead mb-0">
                Assembly using two KUKA iiwa.
                </p><br/>
              <iframe   margin:0; width="512" height="285" src="https://www.youtube.com/embed/kJRFGThzXDQ" frameborder="0" ; allowfullscreen></iframe>
            </div><br/>
            </div>
          </div>
      </section>

    <hr class="m-0">






    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/resume.min.js"></script>

  </body>

</html>
